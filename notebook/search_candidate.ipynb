{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('../data/duyet_word2vec_skill.bin', binary=True)\n",
    "candidate_index_path = '../data/candidate_skills_vector_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def avg_feature_vector(words, model, num_features):\n",
    "        #function to average all words vectors in a given paragraph\n",
    "        featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
    "        nwords = 0\n",
    "\n",
    "        #list containing names of words in the vocabulary\n",
    "        index2word_set = set(model.index2word) # this is moved as input param for performance reasons\n",
    "        for word in words:\n",
    "            if word in index2word_set:\n",
    "                nwords = nwords+1\n",
    "                featureVec = np.add(featureVec, model[word])\n",
    "\n",
    "        if(nwords>0):\n",
    "            featureVec = np.divide(featureVec, nwords)\n",
    "        return featureVec\n",
    "    \n",
    "def find_best_candidate_by_skills(skills, number_of_result = 10):\n",
    "    top_results = []\n",
    "    input_skill_vector = avg_feature_vector(skills.split(), model=model, num_features=300)\n",
    "    \n",
    "    def update_result(top_results, candidate_id, score, number_of_result):\n",
    "        top_results.append({ 'candidate_id': candidate_id, 'score': score })\n",
    "        top_result_sorted = sorted(top_results, key=lambda k: k['score'], reverse=True) \n",
    "        top_results = top_result_sorted[:number_of_result]\n",
    "        return top_results\n",
    "\n",
    "    chunksize = 10 ** 5\n",
    "    for candidates in pd.read_csv(candidate_index_path, chunksize=chunksize, error_bad_lines=False):\n",
    "        for i, candidate in candidates.iterrows():\n",
    "            candidate_feature = candidate[2]\n",
    "            candidate_feature = re.sub(' +', ' ', candidate_feature)\n",
    "            candidate_feature = candidate_feature.replace('\\n', '').replace('[', '').replace(']', '').strip().split(' ')\n",
    "            candidate_feature = np.array(candidate_feature, dtype=\"float32\")\n",
    "            \n",
    "            similarity =  1 - spatial.distance.cosine(input_skill_vector, candidate_feature)\n",
    "            top_results = update_result(top_results, candidate_id=candidate[0], score=similarity, number_of_result=number_of_result)\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'candidate_id': 1446, 'score': 0.90957513929566125},\n",
       " {'candidate_id': 24242, 'score': 0.90686816702549411},\n",
       " {'candidate_id': 22136, 'score': 0.90454623840576864},\n",
       " {'candidate_id': 22122, 'score': 0.89931653774642262},\n",
       " {'candidate_id': 28724, 'score': 0.89899006430681438},\n",
       " {'candidate_id': 11904, 'score': 0.8988085700936127},\n",
       " {'candidate_id': 29372, 'score': 0.89493568996101491},\n",
       " {'candidate_id': 2890, 'score': 0.89356782256672496},\n",
       " {'candidate_id': 24272, 'score': 0.88942238122786865},\n",
       " {'candidate_id': 4660, 'score': 0.88897123928621014}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_candidate_by_skills(\"java c html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<method-wrapper '__getattribute__' of builtin_function_or_method object at 0x7fef6534ad40>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted.__getattribute__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
